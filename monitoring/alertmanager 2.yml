# Alertmanager Configuration for F1-Slipstream Agent
# Handles alert routing and notifications

global:
  resolve_timeout: 5m
  # SMTP configuration for email alerts
  smtp_smarthost: '${SMTP_HOST}:${SMTP_PORT}'
  smtp_from: '${ALERT_EMAIL_FROM}'
  smtp_auth_username: '${SMTP_USERNAME}'
  smtp_auth_password: '${SMTP_PASSWORD}'
  smtp_require_tls: true

# Templates for alert messages
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Route tree for alert distribution
route:
  # Default receiver for all alerts
  receiver: 'default-receiver'
  
  # Group alerts by these labels
  group_by: ['alertname', 'cluster', 'service']
  
  # Wait time before sending initial notification
  group_wait: 30s
  
  # Wait time before sending notification about new alerts in group
  group_interval: 5m
  
  # Wait time before re-sending notification
  repeat_interval: 4h
  
  # Child routes
  routes:
    # Critical alerts - immediate notification
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 10s
      repeat_interval: 1h
      continue: true
    
    # API-specific alerts
    - match:
        component: api
      receiver: 'api-team'
      group_wait: 30s
      repeat_interval: 2h
    
    # Cost alerts
    - match:
        component: cost
      receiver: 'cost-alerts'
      group_wait: 1h
      repeat_interval: 24h
    
    # Infrastructure alerts
    - match:
        component: infrastructure
      receiver: 'infrastructure-team'
      group_wait: 5m
      repeat_interval: 3h

# Alert receivers configuration
receivers:
  # Default receiver - logs only
  - name: 'default-receiver'
    webhook_configs:
      - url: 'http://localhost:9090/api/v1/alerts'
        send_resolved: true

  # Critical alerts - multiple channels
  - name: 'critical-alerts'
    email_configs:
      - to: '${CRITICAL_ALERT_EMAIL}'
        headers:
          Subject: '[CRITICAL] F1-Slipstream Alert: {{ .GroupLabels.alertname }}'
        html: '{{ template "email.default.html" . }}'
        send_resolved: true
    
    # Slack webhook for critical alerts
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#f1-slipstream-critical'
        title: '[CRITICAL] {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
        send_resolved: true
        color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
    
    # PagerDuty for critical alerts (optional)
    # pagerduty_configs:
    #   - service_key: '${PAGERDUTY_SERVICE_KEY}'
    #     description: '{{ .GroupLabels.alertname }}'

  # API team alerts
  - name: 'api-team'
    email_configs:
      - to: '${API_TEAM_EMAIL}'
        headers:
          Subject: '[{{ .Status | toUpper }}] F1-Slipstream API Alert'
        html: '{{ template "email.default.html" . }}'
        send_resolved: true
    
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#f1-slipstream-api'
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
        send_resolved: true

  # Cost alerts
  - name: 'cost-alerts'
    email_configs:
      - to: '${COST_ALERT_EMAIL}'
        headers:
          Subject: '[COST ALERT] F1-Slipstream Usage'
        html: '{{ template "email.default.html" . }}'
        send_resolved: true
    
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#f1-slipstream-costs'
        title: 'Cost Alert: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
        send_resolved: true
        color: 'warning'

  # Infrastructure team alerts
  - name: 'infrastructure-team'
    email_configs:
      - to: '${INFRA_TEAM_EMAIL}'
        headers:
          Subject: '[INFRA] F1-Slipstream Alert'
        html: '{{ template "email.default.html" . }}'
        send_resolved: true

# Inhibition rules - suppress certain alerts when others are firing
inhibit_rules:
  # Inhibit all alerts if API is down
  - source_match:
      alertname: 'APIDown'
    target_match_re:
      alertname: 'API.*'
    equal: ['cluster', 'service']
  
  # Inhibit warning alerts if critical alert is firing
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'cluster', 'service']
